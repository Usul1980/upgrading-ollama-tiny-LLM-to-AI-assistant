{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca8942e",
   "metadata": {},
   "source": [
    "## Offline AI LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60fda2",
   "metadata": {},
   "source": [
    "### Firstly we are going to get text to speech working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5760de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tts we are going to install pyttsx3:\n",
    "# !pip install pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb592df5",
   "metadata": {},
   "source": [
    "#### ok here we test typing in a name for the engine to speak back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82525bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batman\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3  \n",
    "import time\n",
    "# initialize Text-to-speech engine  \n",
    "engine = pyttsx3.init()  \n",
    "# convert this text to speech  \n",
    "\n",
    "text = \"hey, whats your name?\"  \n",
    "engine.say(text)    \n",
    "engine.runAndWait()\n",
    "# play the speech\n",
    "name=input()\n",
    "text1 = name + \", how are you doing?\"  \n",
    "engine.say(text1)  \n",
    "# play the speech  \n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4b026",
   "metadata": {},
   "source": [
    "#### what voices do we have at our disposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b653f73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Voice id=HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-GB_HAZEL_11.0\n",
      "          name=Microsoft Hazel Desktop - English (Great Britain)\n",
      "          languages=[]\n",
      "          gender=None\n",
      "          age=None> HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-GB_HAZEL_11.0\n",
      "<Voice id=HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\n",
      "          name=Microsoft Zira Desktop - English (United States)\n",
      "          languages=[]\n",
      "          gender=None\n",
      "          age=None> HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "for voice in voices:\n",
    "    print(voice, voice.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfea28",
   "metadata": {},
   "source": [
    "### OK now we need a voice recognition tool, we go with vosk because its offline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below worked for me, url is here: https://alphacephei.com/vosk/install\n",
    "# !pip install pyaudio\n",
    "# !pip install vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54cd7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vosk\n",
    "import pyaudio\n",
    "import json\n",
    "\n",
    "model = vosk.Model(lang=\"en-us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54e1f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = vosk.KaldiRecognizer(model, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63b90683",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=16000,\n",
    "                input=True,\n",
    "                frames_per_buffer=1024,\n",
    "                input_device_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a48396b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"recognized_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8da36b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for speech. Say 'Hazel' to stop.\n",
      "i wonder if this speech recognition works hazel\n",
      "Termination keyword detected. Stopping...\n"
     ]
    }
   ],
   "source": [
    "# Open a text file in write mode using a 'with' block\n",
    "\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    print(\"Listening for speech. Say 'Hazel' to stop.\")\n",
    "    # Start streaming and recognize speech\n",
    "    while True:\n",
    "        data = stream.read(1024)#read in chunks of 4096 bytes\n",
    "        if rec.AcceptWaveform(data):#accept waveform of input voice\n",
    "            # Parse the JSON result and get the recognized text\n",
    "            result = json.loads(rec.Result())\n",
    "            recognized_text = result['text']\n",
    "            \n",
    "            # Write recognized text to the file\n",
    "            output_file.write(recognized_text + \"\\n\")\n",
    "            print(recognized_text)\n",
    "            \n",
    "            # Check for the termination keyword\n",
    "            if \"hazel\" in recognized_text.lower():\n",
    "                print(\"Termination keyword detected. Stopping...\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5e9b7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i wonder if this speech recognition works '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_text.replace('hazel', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03f72cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "# Terminate the PyAudio object\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dba26906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id  0  -  Microsoft Sound Mapper - Input\n",
      "Input Device id  1  -  Microphone Array (Realtek High \n"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "for i in range(0, numdevices):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe6858",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25823f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.4-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic<3.0.0,>=2.9.0\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\warren\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\warren\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2021.10.8)\n",
      "Requirement already satisfied: anyio in c:\\users\\warren\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.5.0)\n",
      "Requirement already satisfied: idna in c:\\users\\warren\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.3)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\warren\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Collecting typing-extensions>=4.12.2\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Installing collected packages: typing-extensions, h11, pydantic-core, httpcore, pydantic, httpx, ollama\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.11.0\n",
      "    Uninstalling typing-extensions-4.11.0:\n",
      "      Successfully uninstalled typing-extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic-core 2.20.1\n",
      "    Uninstalling pydantic-core-2.20.1:\n",
      "      Successfully uninstalled pydantic-core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 ollama-0.4.4 pydantic-2.10.4 pydantic-core-2.27.2 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6dc08",
   "metadata": {},
   "source": [
    "### Now pull it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pyttsx3  \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57cd88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is an emerging field that involves using quantum mechanics to perform complex computations, which can be much faster and more efficient than traditional classical computing methods. In 2 sentences:\n",
      "- It's a cutting-edge technology that uses the laws of quantum mechanics to solve problems that would take days or months on classical computers. - Quantum computing is transforming fields such as physics, chemistry, materials science, finance, and healthcare by opening up new possibilities for solving complex problems in record times.\n"
     ]
    }
   ],
   "source": [
    "# lets get some interaction with the tinyllama package of ollama:\n",
    "\n",
    "get_answer = ollama.generate(model='tinyllama',prompt='explain what quantum computing is in 2 sentences')\n",
    "text = get_answer['response'] \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d183ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=16000,\n",
    "                input=True,\n",
    "                frames_per_buffer=1024,\n",
    "                input_device_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35ccbf",
   "metadata": {},
   "source": [
    "#### drum roll............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for speech. Say 'Hazel' to stop.\n",
      "\n",
      "can you explain to me what quantum computing is hazel\n",
      "Quantum computing is a type of computing that involves manipulating and processing information using quantum mechanical properties, which involve the behaviour of atoms and molecules in ways that are inaccessible to classical computers. In contrast to classical computers, where each bit (binary digit) can have only two possible states (0 or 1), quantum bits (qubits) can exist in a superposition of several possible states, with each state carrying information in its own unique manner.\n",
      "\n",
      "The process of computing using quantum algorithms involves the application of specialized hardware and software to perform calculations at a much faster rate than classical computers. Quantum algorithms use quantum mechanics, which is based on the principles of wave function collapse and superposition, to solve complex problems that are not easily solved by classical computers. These algorithms can be used in areas such as drug discovery, finance, cryptography, and physics.\n",
      "\n",
      "Some of the most significant applications of quantum computing include:\n",
      "\n",
      "1. Solving complex mathematical problems more efficiently than classical computers, leading to faster processing speeds and reduced computing time.\n",
      "\n",
      "2. Developing new algorithms for encryption and secure data transfer, as quantum computers are susceptible to attacks that can crack existing encryption methods.\n",
      "\n",
      "3. Investment management: Quantum computing could be used to predict trends in financial markets by analyzing vast amounts of data, providing investors with insights into future market movements.\n",
      "\n",
      "4. Machine learning: Quantum computers are able to solve complex optimization problems that classical computers cannot handle, leading to faster and more accurate results in machine learning and other areas of artificial intelligence.\n",
      "\n",
      "In summary, quantum computing is a groundbreaking technology with enormous potential for advancing fields such as finance, drug discovery, physics, and investment management. As these applications become increasingly important in the modern world, it's clear that we are still at the beginning of this revolutionary process.\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init()  \n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    print(\"Listening for speech. Say 'Hazel' to stop.\")\n",
    "    while True:\n",
    "        data = stream.read(1024)\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            recognized_text = result['text']\n",
    "                \n",
    "            output_file.write(recognized_text + \"\\n\")\n",
    "            print(recognized_text)\n",
    "        \n",
    "            if \"hazel\" in recognized_text.lower():\n",
    "                ques = recognized_text.replace('hazel', '')\n",
    "                get_answer = ollama.generate(model='tinyllama',prompt=ques)\n",
    "                text = get_answer['response'] \n",
    "                print(text)\n",
    "                engine.say(text)    \n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95881cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# being responsible\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
